{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "from IPython.display import Image\n",
    "from shapely.geometry import Point, Polygon\n",
    "from math import factorial\n",
    "import datetime\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from patsy import cr\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan for rough estimate:\n",
    "   1. perennials, and grasses and non irrigated (Why google slide doess not say annuals)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_out_unwanted(dt_df):\n",
    "    unwanted_plants = [\"Almond\", \"Apple\", \"Alfalfa/Grass Hay\",\n",
    "                       \"Apricot\", \"Asparagus\", \"Berry, Unknown\",  \n",
    "                       \"Blueberry\", \"Cherry\", \"Grape, Juice\", \n",
    "                       \"Grape, Table\", \"Grape, Unknown\", \n",
    "                       \"Grape, Wine\", \"Hops\", \"Mint\", \n",
    "                       \"Nectarine/Peach\", \"Orchard, Unknown\", \n",
    "                       \"Pear\", \"Plum\", \"Strawberry\", \"Walnut\"]\n",
    "    \n",
    "    # filter unwanted plants\n",
    "    dt_df = dt_df[~(dt_df['CropTyp'].isin(unwanted_plants))]\n",
    "    \n",
    "    # filter non-irrigated\n",
    "    \"\"\"\n",
    "    # These two lines can replace the following two lines\n",
    "    non_irrigations = [\"Unknown\", \"None\", \"None/Rill\", \"None/Sprinkler\", \n",
    "                       \"None/Sprinkler/Wheel Line\", \n",
    "                       \"None/Wheel Line\", \"Drip/None\", \"Center Pivot/None\"]\n",
    "    \n",
    "    dt_df = dt_df[~(dt_df['Irrigtn'].isin(non_irrigations))]\n",
    "    \"\"\"\n",
    "    dt_df = dt_df[~dt_df['Irrigtn'].str.contains(\"None\")]\n",
    "    dt_df = dt_df[~dt_df['Irrigtn'].str.contains(\"Unknown\")]\n",
    "    \n",
    "    return dt_df\n",
    "    \n",
    "def initial_clean(dt):\n",
    "    # remove the useles system:index column\n",
    "    if (\"system:index\" in list(grant_2018.columns)):\n",
    "        dt = dt.drop(columns=['system:index'])\n",
    "    \n",
    "    # Drop rows whith NA in NDVI column.\n",
    "    dt = dt[dt['NDVI'].notna()]\n",
    "    \n",
    "    # rename the column .geo to \"geo\"\n",
    "    dt = dt.rename(columns={\".geo\": \"geo\"})\n",
    "    \n",
    "    return (dt)\n",
    "\n",
    "def order_by_doy(dt):\n",
    "    return dt.sort_values(by='doy', axis=0, ascending=True)\n",
    "\n",
    "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
    "    \"\"\"\n",
    "    Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
    "    The Savitzky-Golay filter removes high frequency noise from data.\n",
    "    It has the advantage of preserving the original shape and\n",
    "    features of the signal better than other types of filtering\n",
    "    approaches, such as moving averages techniques.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like, shape (N,)\n",
    "        the values of the time history of the signal.\n",
    "    window_size : int\n",
    "        the length of the window. Must be an odd integer number.\n",
    "    order : int\n",
    "        the order of the polynomial used in the filtering.\n",
    "        Must be less then `window_size` - 1.\n",
    "    deriv: int\n",
    "        the order of the derivative to compute (default = 0 means only smoothing)\n",
    "    Returns\n",
    "    -------\n",
    "    ys : ndarray, shape (N)\n",
    "        the smoothed signal (or it's n-th derivative).\n",
    "    Notes\n",
    "    -----\n",
    "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
    "    suited for smoothing noisy data. The main idea behind this\n",
    "    approach is to make for each point a least-square fit with a\n",
    "    polynomial of high order over a odd-sized window centered at\n",
    "    the point.\n",
    "    Examples\n",
    "    --------\n",
    "    t = np.linspace(-4, 4, 500)\n",
    "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
    "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(t, y, label='Noisy signal')\n",
    "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
    "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
    "       Data by Simplified Least Squares Procedures. Analytical\n",
    "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
    "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
    "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
    "       Cambridge University Press ISBN-13: 9780521880688\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        window_size = np.abs(np.int(window_size))\n",
    "        order = np.abs(np.int(order))\n",
    "    except ValueError:\n",
    "        raise ValueError(\"window_size and order have to be of type int\")\n",
    "    if window_size % 2 != 1 or window_size < 1:\n",
    "        raise TypeError(\"window_size size must be a positive odd number\")\n",
    "    if window_size < order + 2:\n",
    "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
    "    order_range = range(order+1)\n",
    "    half_window = (window_size -1) // 2\n",
    "    \n",
    "    y_array = np.array(y)\n",
    "    # precompute coefficients\n",
    "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
    "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
    "    # pad the signal at the extremes with\n",
    "    # values taken from the signal itself\n",
    "    firstvals = y_array[0] - np.abs( y_array[1:half_window+1][::-1] - y_array[0] )\n",
    "    lastvals = y_array[-1] + np.abs(y_array[-half_window-1:-1][::-1] - y_array[-1])\n",
    "    y_array = np.concatenate((firstvals, y_array, lastvals))\n",
    "    return np.convolve( m[::-1], y_array, mode='valid')\n",
    "\n",
    "\n",
    "def _datacheck_peakdetect(x_axis, y_axis):\n",
    "    if x_axis is None:\n",
    "        x_axis = range(len(y_axis))\n",
    "    \n",
    "    if len(y_axis) != len(x_axis):\n",
    "        raise (ValueError, \n",
    "                'Input vectors y_axis and x_axis must have same length')\n",
    "    \n",
    "    #needs to be a numpy array\n",
    "    y_axis = np.array(y_axis)\n",
    "    x_axis = np.array(x_axis)\n",
    "    return x_axis, y_axis\n",
    "\n",
    "def peakdetect(y_axis, x_axis = None, lookahead = 300, delta=0):\n",
    "    \"\"\"\n",
    "    Converted from/based on a MATLAB script at: \n",
    "    http://billauer.co.il/peakdet.html\n",
    "    \n",
    "    https://github.com/mattijn/pynotebook/blob/16fe0f58624938b82d93cbd208b8cb871ab95ec1/\n",
    "    ipynotebooks/Python2.7/.ipynb_checkpoints/PLOTS%20SIGNAL%20PROCESSING-P1%20and%20P2-checkpoint.ipynb\n",
    "     \n",
    "    also look at: https://gist.github.com/endolith/250860\n",
    "    and \n",
    "    http://billauer.co.il/peakdet.html\n",
    "    \n",
    "    \n",
    "    \n",
    "    function for detecting local maximas and minmias in a signal.\n",
    "    Discovers peaks by searching for values which are surrounded by lower\n",
    "    or larger values for maximas and minimas respectively\n",
    "    \n",
    "    keyword arguments:\n",
    "    y_axis -- A list containg the signal over which to find peaks\n",
    "    x_axis -- (optional) A x-axis whose values correspond to the y_axis list\n",
    "        and is used in the return to specify the postion of the peaks. If\n",
    "        omitted an index of the y_axis is used. (default: None)\n",
    "    lookahead -- (optional) distance to look ahead from a peak candidate to\n",
    "        determine if it is the actual peak (default: 200) \n",
    "        '(sample / period) / f' where '4 >= f >= 1.25' might be a good value\n",
    "    delta -- (optional) this specifies a minimum difference between a peak and\n",
    "        the following points, before a peak may be considered a peak. Useful\n",
    "        to hinder the function from picking up false peaks towards to end of\n",
    "        the signal. To work well delta should be set to delta >= RMSnoise * 5.\n",
    "        (default: 0)\n",
    "            delta function causes a 20% decrease in speed, when omitted\n",
    "            Correctly used it can double the speed of the function\n",
    "    \n",
    "    return -- two lists [max_peaks, min_peaks] containing the positive and\n",
    "        negative peaks respectively. Each cell of the lists contains a tupple\n",
    "        of: (position, peak_value) \n",
    "        to get the average peak value do: np.mean(max_peaks, 0)[1] on the\n",
    "        results to unpack one of the lists into x, y coordinates do: \n",
    "        x, y = zip(*tab)\n",
    "    \"\"\"\n",
    "    max_peaks = []\n",
    "    min_peaks = []\n",
    "    dump = []   #Used to pop the first hit which almost always is false\n",
    "       \n",
    "    # check input data\n",
    "    x_axis, y_axis = _datacheck_peakdetect(x_axis, y_axis)\n",
    "    # store data length for later use\n",
    "    length = len(y_axis)\n",
    "    \n",
    "    \n",
    "    #perform some checks\n",
    "    if lookahead < 1:\n",
    "        raise ValueError ( \"Lookahead must be '1' or above in value\")\n",
    "    if not (np.isscalar(delta) and delta >= 0):\n",
    "        raise ValueError ( \"delta must be a positive number\" )\n",
    "    \n",
    "    #maxima and minima candidates are temporarily stored in\n",
    "    #mx and mn respectively\n",
    "    mn, mx = np.Inf, -np.Inf\n",
    "    \n",
    "    #Only detect peak if there is 'lookahead' amount of points after it\n",
    "    for index, (x, y) in enumerate(zip(x_axis[:-lookahead], \n",
    "                                        y_axis[:-lookahead])):\n",
    "        if y > mx:\n",
    "            mx = y\n",
    "            mxpos = x\n",
    "        if y < mn:\n",
    "            mn = y\n",
    "            mnpos = x\n",
    "        \n",
    "        ####look for max####\n",
    "        if y < mx-delta and mx != np.Inf:\n",
    "            #Maxima peak candidate found\n",
    "            #look ahead in signal to ensure that this is a peak and not jitter\n",
    "            if y_axis[index:index+lookahead].max() < mx:\n",
    "                max_peaks.append([mxpos, mx])\n",
    "                dump.append(True)\n",
    "                #set algorithm to only find minima now\n",
    "                mx = np.Inf\n",
    "                mn = np.Inf\n",
    "                if index+lookahead >= length:\n",
    "                    #end is within lookahead no more peaks can be found\n",
    "                    break\n",
    "                continue\n",
    "            #else:  #slows shit down this does\n",
    "            #    mx = ahead\n",
    "            #    mxpos = x_axis[np.where(y_axis[index:index+lookahead]==mx)]\n",
    "        \n",
    "        ####look for min####\n",
    "        if y > mn+delta and mn != -np.Inf:\n",
    "            #Minima peak candidate found \n",
    "            #look ahead in signal to ensure that this is a peak and not jitter\n",
    "            if y_axis[index:index+lookahead].min() > mn:\n",
    "                min_peaks.append([mnpos, mn])\n",
    "                dump.append(False)\n",
    "                #set algorithm to only find maxima now\n",
    "                mn = -np.Inf\n",
    "                mx = -np.Inf\n",
    "                if index+lookahead >= length:\n",
    "                    #end is within lookahead no more peaks can be found\n",
    "                    break\n",
    "            #else:  #slows shit down this does\n",
    "            #    mn = ahead\n",
    "            #    mnpos = x_axis[np.where(y_axis[index:index+lookahead]==mn)]\n",
    "    \n",
    "    \n",
    "    #Remove the false hit on the first value of the y_axis\n",
    "    try:\n",
    "        if dump[0]:\n",
    "            max_peaks.pop(0)\n",
    "        else:\n",
    "            min_peaks.pop(0)\n",
    "        del dump\n",
    "    except IndexError:\n",
    "        # no peaks were found, should the function return empty lists?\n",
    "        pass\n",
    "        \n",
    "    return [max_peaks, min_peaks]\n",
    "\n",
    "def form_xs_ys_from_peakdetect(max_peak_list, doy_vect):\n",
    "    dd = np.array(doy_vect)\n",
    "    xs = np.zeros(len(max_peak_list))\n",
    "    ys = np.zeros(len(max_peak_list))\n",
    "    for ii in range(len(max_peak_list)):  \n",
    "        xs[ii] = dd[int(max_peak_list[ii][0])]\n",
    "        ys[ii] = max_peak_list[ii][1]\n",
    "    return (xs, ys)\n",
    "\n",
    "def keep_WSDA_columns(dt_dt):\n",
    "    needed_columns = ['Acres', 'CovrCrp', 'CropGrp', 'CropTyp',\n",
    "                      'DataSrc', 'ExctAcr', 'IntlSrD', 'Irrigtn', 'LstSrvD', 'Notes',\n",
    "                      'RtCrpTy', 'Shap_Ar', 'Shp_Lng', 'TRS', 'county', 'year', 'geo']\n",
    "    \"\"\"\n",
    "    # Using DataFrame.drop\n",
    "    df.drop(df.columns[[1, 2]], axis=1, inplace=True)\n",
    "\n",
    "    # drop by Name\n",
    "    df1 = df1.drop(['B', 'C'], axis=1)\n",
    "    \"\"\"\n",
    "    dt_dt = dt_dt[needed_columns]\n",
    "    return dt_dt\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/hn/Documents/01_research_data/Ag_check_point/remote_sensing/01_NDVI_TS/Grant/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\"Grant_2018_TS.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_N = file_names[0]\n",
    "grant_2018 = pd.read_csv(data_dir + file_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "385\n",
      "385\n"
     ]
    }
   ],
   "source": [
    "# Count distict values, use nunique:\n",
    "pprint (grant_2018['.geo'].nunique())\n",
    "\n",
    "# Count only non-null values, use count:\n",
    "print (grant_2018['.geo'].count())\n",
    "\n",
    "# Count total values including null values, use size attribute:\n",
    "print (grant_2018['.geo'].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of unique polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_list = grant_2018['.geo'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick one of the polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_grant_2018_field = grant_2018[grant_2018['.geo']==polygon_list[3]]\n",
    "a_grant_2018_field = order_by_doy(a_grant_2018_field)\n",
    "a_grant_2018_field.loc[165, 'CropTyp'] = \"Almond\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 24)\n"
     ]
    }
   ],
   "source": [
    "print(a_grant_2018_field.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data before cleaning is of size (57, 24)\n",
      "The data after cleaning is of size (55, 23)\n"
     ]
    }
   ],
   "source": [
    "print (\"The data before cleaning is of size\", str(a_grant_2018_field.shape))\n",
    "grant_2018_cleaned = initial_clean(a_grant_2018_field)\n",
    "print (\"The data after cleaning is of size\", str(grant_2018_cleaned.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Acres', 'B2', 'B3', 'B4', 'B8', 'CovrCrp', 'CropGrp', 'CropTyp',\n",
       "       'DataSrc', 'ExctAcr', 'IntlSrD', 'Irrigtn', 'LstSrvD', 'NDVI', 'Notes',\n",
       "       'RtCrpTy', 'Shap_Ar', 'Shp_Lng', 'TRS', 'county', 'doy', 'year', 'geo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant_2018_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acres</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B8</th>\n",
       "      <th>CovrCrp</th>\n",
       "      <th>CropGrp</th>\n",
       "      <th>CropTyp</th>\n",
       "      <th>DataSrc</th>\n",
       "      <th>ExctAcr</th>\n",
       "      <th>...</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>Notes</th>\n",
       "      <th>RtCrpTy</th>\n",
       "      <th>Shap_Ar</th>\n",
       "      <th>Shp_Lng</th>\n",
       "      <th>TRS</th>\n",
       "      <th>county</th>\n",
       "      <th>doy</th>\n",
       "      <th>year</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>3</td>\n",
       "      <td>0.616430</td>\n",
       "      <td>0.570890</td>\n",
       "      <td>0.645604</td>\n",
       "      <td>0.620327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cereal Grain</td>\n",
       "      <td>Almond</td>\n",
       "      <td>NASS</td>\n",
       "      <td>3.424051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>13856.641211</td>\n",
       "      <td>773.171544</td>\n",
       "      <td>T27R29E31</td>\n",
       "      <td>Grant</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[-119.233717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>3</td>\n",
       "      <td>0.241529</td>\n",
       "      <td>0.205338</td>\n",
       "      <td>0.223465</td>\n",
       "      <td>0.233155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cereal Grain</td>\n",
       "      <td>Wheat Fallow</td>\n",
       "      <td>NASS</td>\n",
       "      <td>3.424051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>13856.641211</td>\n",
       "      <td>773.171544</td>\n",
       "      <td>T27R29E31</td>\n",
       "      <td>Grant</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[-119.233717...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Acres        B2        B3        B4        B8  CovrCrp       CropGrp  \\\n",
       "165      3  0.616430  0.570890  0.645604  0.620327      NaN  Cereal Grain   \n",
       "166      3  0.241529  0.205338  0.223465  0.233155      NaN  Cereal Grain   \n",
       "\n",
       "          CropTyp DataSrc   ExctAcr  ...      NDVI Notes RtCrpTy  \\\n",
       "165        Almond    NASS  3.424051  ... -0.019440   NaN   Wheat   \n",
       "166  Wheat Fallow    NASS  3.424051  ...  0.026045   NaN   Wheat   \n",
       "\n",
       "          Shap_Ar     Shp_Lng        TRS  county   doy    year  \\\n",
       "165  13856.641211  773.171544  T27R29E31   Grant   2.0  2018.0   \n",
       "166  13856.641211  773.171544  T27R29E31   Grant  29.0  2018.0   \n",
       "\n",
       "                                                   geo  \n",
       "165  {\"type\":\"Polygon\",\"coordinates\":[[[-119.233717...  \n",
       "166  {\"type\":\"Polygon\",\"coordinates\":[[[-119.233717...  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant_2018_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NASS'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grant_2018_cleaned['DataSrc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 23)\n"
     ]
    }
   ],
   "source": [
    "print(grant_2018_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 23)\n",
      "(55, 17)\n"
     ]
    }
   ],
   "source": [
    "A = keep_WSDA_columns(grant_2018_cleaned)\n",
    "print(grant_2018_cleaned.shape)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 17)\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 23)\n"
     ]
    }
   ],
   "source": [
    "print(grant_2018_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.iloc[0, 3] == A.iloc[1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acres</th>\n",
       "      <th>CovrCrp</th>\n",
       "      <th>CropGrp</th>\n",
       "      <th>CropTyp</th>\n",
       "      <th>DataSrc</th>\n",
       "      <th>ExctAcr</th>\n",
       "      <th>IntlSrD</th>\n",
       "      <th>Irrigtn</th>\n",
       "      <th>LstSrvD</th>\n",
       "      <th>Notes</th>\n",
       "      <th>RtCrpTy</th>\n",
       "      <th>Shap_Ar</th>\n",
       "      <th>Shp_Lng</th>\n",
       "      <th>TRS</th>\n",
       "      <th>county</th>\n",
       "      <th>year</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cereal Grain</td>\n",
       "      <td>Almond</td>\n",
       "      <td>NASS</td>\n",
       "      <td>3.424051</td>\n",
       "      <td>2005/01/03 00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2018/12/31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>13856.641211</td>\n",
       "      <td>773.171544</td>\n",
       "      <td>T27R29E31</td>\n",
       "      <td>Grant</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[-119.233717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cereal Grain</td>\n",
       "      <td>Wheat Fallow</td>\n",
       "      <td>NASS</td>\n",
       "      <td>3.424051</td>\n",
       "      <td>2005/01/03 00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2018/12/31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>13856.641211</td>\n",
       "      <td>773.171544</td>\n",
       "      <td>T27R29E31</td>\n",
       "      <td>Grant</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[-119.233717...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Acres  CovrCrp       CropGrp       CropTyp DataSrc   ExctAcr  \\\n",
       "165      3      NaN  Cereal Grain        Almond    NASS  3.424051   \n",
       "166      3      NaN  Cereal Grain  Wheat Fallow    NASS  3.424051   \n",
       "\n",
       "                 IntlSrD Irrigtn              LstSrvD Notes RtCrpTy  \\\n",
       "165  2005/01/03 00:00:00    None  2018/12/31 00:00:00   NaN   Wheat   \n",
       "166  2005/01/03 00:00:00    None  2018/12/31 00:00:00   NaN   Wheat   \n",
       "\n",
       "          Shap_Ar     Shp_Lng        TRS county    year  \\\n",
       "165  13856.641211  773.171544  T27R29E31  Grant  2018.0   \n",
       "166  13856.641211  773.171544  T27R29E31  Grant  2018.0   \n",
       "\n",
       "                                                   geo  \n",
       "165  {\"type\":\"Polygon\",\"coordinates\":[[[-119.233717...  \n",
       "166  {\"type\":\"Polygon\",\"coordinates\":[[[-119.233717...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.iloc[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = A.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = B.drop(['CropTyp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = B.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acres</th>\n",
       "      <th>CovrCrp</th>\n",
       "      <th>CropGrp</th>\n",
       "      <th>DataSrc</th>\n",
       "      <th>ExctAcr</th>\n",
       "      <th>IntlSrD</th>\n",
       "      <th>Irrigtn</th>\n",
       "      <th>LstSrvD</th>\n",
       "      <th>Notes</th>\n",
       "      <th>RtCrpTy</th>\n",
       "      <th>Shap_Ar</th>\n",
       "      <th>Shp_Lng</th>\n",
       "      <th>TRS</th>\n",
       "      <th>county</th>\n",
       "      <th>year</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cereal Grain</td>\n",
       "      <td>NASS</td>\n",
       "      <td>3.424051</td>\n",
       "      <td>2005/01/03 00:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2018/12/31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>13856.641211</td>\n",
       "      <td>773.171544</td>\n",
       "      <td>T27R29E31</td>\n",
       "      <td>Grant</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>{\"type\":\"Polygon\",\"coordinates\":[[[-119.233717...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Acres  CovrCrp       CropGrp DataSrc   ExctAcr              IntlSrD  \\\n",
       "165      3      NaN  Cereal Grain    NASS  3.424051  2005/01/03 00:00:00   \n",
       "\n",
       "    Irrigtn              LstSrvD Notes RtCrpTy       Shap_Ar     Shp_Lng  \\\n",
       "165    None  2018/12/31 00:00:00   NaN   Wheat  13856.641211  773.171544   \n",
       "\n",
       "           TRS county    year  \\\n",
       "165  T27R29E31  Grant  2018.0   \n",
       "\n",
       "                                                   geo  \n",
       "165  {\"type\":\"Polygon\",\"coordinates\":[[[-119.233717...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
